# TechWatch AI - Plateforme de Veille Technologique Intelligente

## Description du projet

TechWatch est une plateforme de veille technologique personnalis√©e qui automatise la collecte, l'analyse et la pr√©sentation d'informations tech pertinentes.
Le syst√®me scrappe des sources multiples (Reddit, HackerNews, Dev.to, Medium, GitHub Trending), utilise du NLP pour scorer les articles selon les mots-cl√©s de l'utilisateur, g√©n√®re des r√©sum√©s IA via l'API Claude, et pr√©sente les donn√©es via des dashboards Power BI interactifs.
L'objectif est de remplacer 2h de veille manuelle quotidienne par un syst√®me intelligent qui livre les top articles pertinents chaque matin.

## Stack technique

### Frontend (Dashboard Web)

- **Framework**: Next.js 14 (App Router)
- **Language**: TypeScript
- **Styling**: TailwindCSS + shadcn/ui (Composants)
- **State Management**: Zustand (Global), TanStack Query (Server state)
- **Forms**: React Hook Form + Zod (Validation)
- **Charts**: Recharts (graphiques frontend)
- **Icons**: Lucide React

### Backend (API & ETL)

- **Language**: Python 3.11+
- **Framework**: FastAPI (API REST moderne)
- **ORM**: SQLAlchemy 2.0 (avec typage)
- **Validation**: Pydantic V2
- **Database**: PostgreSQL 16 (driver: asyncpg)
- **Cache & Queue**: Redis 7
- **Task Queue**: Celery + Redis (scraping automatique)
- **HTTP Client**: httpx (async)
- **AI Integration**: Anthropic API (Claude Sonnet 4)
- **NLP**: spaCy (fr_core_news_lg / en_core_web_lg)
- **ML Scoring**: scikit-learn (TF-IDF, cosine similarity)

### Scraping Workers

- **Scrapers**: Modules Python async (httpx + BeautifulSoup 4)
- **Sources**:
  - Reddit (API OAuth2)
  - HackerNews (Firebase API)
  - Dev.to (API REST)
  - GitHub Trending (scraping HTML)
  - Medium (RSS)
  - Twitter/X (API v2, optionnel)

### Business Intelligence

- **Power BI Desktop**: Dashboards interactifs
- **Power BI Embedded**: Int√©gration dans le frontend Next.js
- **DAX**: Mesures et KPIs personnalis√©s
- **SQL Views**: Vues optimis√©es pour Power BI

### Infrastructure

- **Containerization**: Docker & Docker Compose
- **CI/CD**: GitHub Actions
- **Linting**: Ruff (Python), ESLint + Biome (TypeScript)
- **Testing**: Pytest (Backend), Vitest (Frontend)

## Architecture du projet (Monorepo)

### Structure des dossiers

```
techwatch/
‚îú‚îÄ‚îÄ üìÇ .github/                 # CI/CD Workflows
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ backend-ci.yml
‚îÇ       ‚îî‚îÄ‚îÄ frontend-ci.yml
‚îÇ
‚îú‚îÄ‚îÄ üìÇ infra/                   # Docker, Nginx, Postgres configs
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îú‚îÄ‚îÄ postgres/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ init.sql
‚îÇ   ‚îî‚îÄ‚îÄ nginx/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ backend/                 # API Python FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Entrypoint FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Settings (Pydantic)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py        # SQLAlchemy engine & session
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/            # SQLAlchemy Models (Tables DB)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ article.py     # Table articles
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword.py     # Table keywords
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ source.py      # Table sources (Reddit, HN...)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user_config.py # Config utilisateur
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/           # Pydantic Schemas (DTO/validation)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ article.py     # ArticleResponse, ArticleCreate
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyword.py     # KeywordCreate, KeywordUpdate
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py      # UserConfigUpdate
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/               # Routes API REST
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deps.py        # Dependencies injection
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ articles.py    # GET/POST /api/articles
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keywords.py    # CRUD mots-cl√©s
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources.py     # CRUD sources
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analytics.py   # Stats & tendances
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scrapers/          # Modules de scraping
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py        # BaseScraper (classe abstraite)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reddit.py      # RedditScraper
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hackernews.py  # HackerNewsScraper
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devto.py       # DevToScraper
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github.py      # GitHubTrendingScraper
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medium.py      # MediumRSSScraper
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ factory.py     # ScraperFactory (pattern)
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlp/               # Natural Language Processing
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scorer.py      # ArticleScorer (spaCy + TF-IDF)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarizer.py  # ArticleSummarizer (Claude API)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ categorizer.py # Auto-cat√©gorisation
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deduplicator.py # D√©tection doublons
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/             # Celery Tasks (async jobs)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py  # Config Celery
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping.py    # Task: scrape_all_sources
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scoring.py     # Task: score_articles
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ email.py       # Task: send_daily_digest
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ logger.py      # Logging config
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ email_sender.py # SMTP email
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ alembic/               # Migrations DB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ env.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_scrapers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_nlp/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_api/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml         # Poetry dependencies
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îÇ
‚îú‚îÄ‚îÄ üìÇ frontend/                # Next.js React
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx           # Dashboard principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx       # Gestion mots-cl√©s
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analytics/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx       # Analytics avanc√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api/               # API Routes Next.js
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ powerbi/       # Proxy Power BI Embedded
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/                # shadcn/ui components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ArticleCard.tsx    # Carte article
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ KeywordManager.tsx # Gestion mots-cl√©s
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SourceToggle.tsx   # Toggle sources on/off
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TrendChart.tsx     # Graphiques tendances
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PowerBIDashboard.tsx # Embed Power BI
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api-client.ts      # Client axios pour backend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils.ts           # Helpers (cn, formatDate...)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validators.ts      # Zod schemas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useArticles.ts     # TanStack Query hook
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useKeywords.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useTrends.ts
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ store/                 # Zustand stores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config-store.ts    # State config globale
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui-store.ts        # State UI (modals, etc)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts           # Types TypeScript
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.ts
‚îÇ   ‚îî‚îÄ‚îÄ next.config.js
‚îÇ
‚îú‚îÄ‚îÄ üìÇ database/
‚îÇ   ‚îú‚îÄ‚îÄ init.sql               # Script initialisation
‚îÇ   ‚îî‚îÄ‚îÄ powerbi/
‚îÇ       ‚îú‚îÄ‚îÄ views.sql          # Vues SQL pour Power BI
‚îÇ       ‚îî‚îÄ‚îÄ measures.dax       # Mesures DAX templates
‚îÇ
‚îú‚îÄ‚îÄ üìÇ powerbi/
‚îÇ   ‚îú‚îÄ‚îÄ TechWatch.pbix         # Fichier Power BI Desktop
‚îÇ   ‚îî‚îÄ‚îÄ reports/
‚îÇ       ‚îú‚îÄ‚îÄ daily-stats.pbix
‚îÇ       ‚îî‚îÄ‚îÄ trends.pbix
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```

## Sch√©ma Base de Donn√©es PostgreSQL

### Tables principales

**sources** - Sources de scraping

```sql
- id (SERIAL PRIMARY KEY)
- name (VARCHAR) - "Reddit", "HackerNews"...
- type (VARCHAR) - "reddit", "hackernews"...
- base_url (TEXT)
- is_active (BOOLEAN)
- scrape_frequency_hours (INTEGER)
- last_scraped_at (TIMESTAMP)
- config (JSONB) - Config sp√©cifique
- created_at, updated_at
```

**keywords** - Mots-cl√©s utilisateur

```sql
- id (SERIAL PRIMARY KEY)
- keyword (VARCHAR) - "FHIR", "blockchain"...
- category (VARCHAR) - "healthtech", "web3"...
- weight (FLOAT) - Importance 1.0-5.0
- is_active (BOOLEAN)
- created_at, updated_at
```

**articles** - Articles scrap√©s et analys√©s

```sql
- id (SERIAL PRIMARY KEY)
- source_id (FK ‚Üí sources)
- external_id (VARCHAR) - ID sur source externe
- title (TEXT)
- url (TEXT UNIQUE)
- content (TEXT)
- summary (TEXT) - R√©sum√© g√©n√©r√© par IA
- author (VARCHAR)
- published_at (TIMESTAMP)
- scraped_at (TIMESTAMP)
- score (FLOAT) - Score pertinence 0-100
- category (VARCHAR) - Cat√©gorie auto-d√©tect√©e
- tags (TEXT[]) - Array de tags
- language (VARCHAR)
- read_time_minutes (INTEGER)
- upvotes, comments_count (INTEGER)
- is_read, is_favorite, is_archived (BOOLEAN)
- created_at, updated_at
```

**article_keywords** - Relation N:N

```sql
- id (SERIAL PRIMARY KEY)
- article_id (FK ‚Üí articles)
- keyword_id (FK ‚Üí keywords)
- relevance_score (FLOAT) - Score pour ce keyword
- created_at
```

**trends** - Tendances d√©tect√©es

```sql
- id (SERIAL PRIMARY KEY)
- keyword (VARCHAR)
- category (VARCHAR)
- trend_score (FLOAT) - Score de tendance
- article_count (INTEGER)
- date (DATE)
- created_at
```

**user_config** - Configuration utilisateur

```sql
- id (SERIAL PRIMARY KEY)
- email (VARCHAR)
- daily_digest_enabled (BOOLEAN)
- digest_time (TIME)
- min_score_threshold (FLOAT)
- preferred_categories (TEXT[])
- email_frequency (VARCHAR) - "daily", "weekly"
- created_at, updated_at
```

### Vues SQL pour Power BI

**vw_articles_daily_stats**

```sql
SELECT
    DATE(published_at) as date,
    category,
    COUNT(*) as article_count,
    AVG(score) as avg_score,
    SUM(CASE WHEN is_read THEN 1 ELSE 0 END) as read_count
FROM articles
GROUP BY DATE(published_at), category;
```

**vw_weekly_trends**

```sql
SELECT
    DATE_TRUNC('week', date) as week_start,
    keyword,
    AVG(trend_score) as avg_trend_score,
    SUM(article_count) as total_articles
FROM trends
GROUP BY week_start, keyword;
```

## Conventions de code

### Naming Conventions

**Python (Backend)**

- `snake_case` pour variables, fonctions, modules
- `PascalCase` pour Classes, Pydantic Models
- `SCREAMING_SNAKE_CASE` pour constantes
- Pr√©fixe priv√© : `_function_name`
- Async functions : `async def fetch_articles()`

**TypeScript (Frontend)**

- `PascalCase` pour Composants React (`ArticleCard.tsx`)
- `camelCase` pour variables, fonctions
- `usePrefix` pour hooks custom (`useArticles`)
- `SCREAMING_SNAKE_CASE` pour constantes globales
- Interfaces : pr√©fixe `I` optionnel (`IArticle` ou `Article`)

**SQL**

- Tables : `snake_case` pluriel (`articles`, `keywords`)
- Colonnes : `snake_case` (`created_at`, `is_active`)
- Vues : pr√©fixe `vw_` (`vw_daily_stats`)
- Index : pr√©fixe `idx_` (`idx_articles_score`)

### Structure Composant React (Exemple)

```typescript
'use client';

import { useState } from 'react';
import { format } from 'date-fns';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { ExternalLink, Star } from 'lucide-react';
import type { Article } from '@/types';

interface ArticleCardProps {
  article: Article;
  onToggleFavorite?: (id: string) => void;
  onMarkRead?: (id: string) => void;
}

export const ArticleCard = ({
  article,
  onToggleFavorite,
  onMarkRead
}: ArticleCardProps) => {
  const [isExpanded, setIsExpanded] = useState(false);

  // Early return si donn√©es invalides
  if (!article.title || !article.url) return null;

  return (
    <div className="border rounded-lg p-4 shadow-sm hover:shadow-md transition-shadow">
      {/* Header */}
      <div className="flex items-start justify-between gap-4">
        <div className="flex-1">
          <h3 className="font-bold text-lg leading-tight">
            {article.title}
          </h3>
          <div className="flex items-center gap-2 mt-1 text-sm text-muted-foreground">
            <span>{article.source?.name}</span>
            <span>‚Ä¢</span>
            <span>{format(new Date(article.published_at), 'dd MMM yyyy')}</span>
            {article.read_time_minutes && (
              <>
                <span>‚Ä¢</span>
                <span>{article.read_time_minutes} min</span>
              </>
            )}
          </div>
        </div>

        {/* Score badge */}
        <Badge
          variant={article.score > 70 ? 'default' : 'secondary'}
          className="shrink-0"
        >
          {article.score.toFixed(0)}
        </Badge>
      </div>

      {/* Tags */}
      <div className="flex flex-wrap gap-2 my-3">
        <Badge variant="outline">{article.category}</Badge>
        {article.tags?.slice(0, 3).map((tag) => (
          <Badge key={tag} variant="secondary">
            {tag}
          </Badge>
        ))}
      </div>

      {/* Summary (conditionnel) */}
      {isExpanded && article.summary && (
        <p className="text-sm text-muted-foreground my-3 leading-relaxed">
          {article.summary}
        </p>
      )}

      {/* Actions */}
      <div className="flex items-center gap-2 mt-3">
        <Button
          variant="ghost"
          size="sm"
          onClick={() => setIsExpanded(!isExpanded)}
        >
          {isExpanded ? 'R√©duire' : 'Voir r√©sum√©'}
        </Button>

        <Button
          variant="ghost"
          size="sm"
          onClick={() => onToggleFavorite?.(article.id)}
        >
          <Star className={article.is_favorite ? 'fill-current' : ''} />
        </Button>

        <Button
          variant="ghost"
          size="sm"
          asChild
        >
          <a href={article.url} target="_blank" rel="noopener noreferrer">
            <ExternalLink className="w-4 h-4" />
          </a>
        </Button>
      </div>
    </div>
  );
};
```

### Structure Service Python (Exemple)

```python
from typing import List, Dict, Optional
from sqlalchemy.orm import Session
from app.models.article import Article
from app.models.keyword import Keyword
from app.nlp.scorer import ArticleScorer
from app.utils.logger import get_logger

logger = get_logger(__name__)

class ArticleService:
    """Service m√©tier pour la gestion des articles"""

    def __init__(self, db: Session):
        self.db = db
        self.scorer = ArticleScorer()

    async def get_articles(
        self,
        category: Optional[str] = None,
        min_score: float = 0.0,
        limit: int = 50,
        offset: int = 0
    ) -> List[Article]:
        """
        R√©cup√®re les articles avec filtres

        Args:
            category: Filtrer par cat√©gorie
            min_score: Score minimum
            limit: Nombre max de r√©sultats
            offset: Offset pour pagination

        Returns:
            Liste d'articles tri√©s par score d√©croissant
        """
        query = self.db.query(Article).filter(
            Article.score >= min_score,
            Article.is_archived == False
        )

        if category:
            query = query.filter(Article.category == category)

        articles = query.order_by(
            Article.score.desc()
        ).limit(limit).offset(offset).all()

        logger.info(f"Retrieved {len(articles)} articles")
        return articles

    async def score_article(
        self,
        article: Article,
        keywords: List[Keyword]
    ) -> float:
        """
        Score un article selon les mots-cl√©s

        Args:
            article: Article √† scorer
            keywords: Liste des mots-cl√©s actifs

        Returns:
            Score de pertinence 0-100
        """
        try:
            text = f"{article.title} {article.content or ''}"
            keyword_data = [
                {
                    "keyword": kw.keyword,
                    "weight": kw.weight,
                    "category": kw.category
                }
                for kw in keywords
            ]

            result = self.scorer.score_article(text, keyword_data)

            # Update article
            article.score = result["overall_score"]
            article.category = result["category"]
            self.db.commit()

            return result["overall_score"]

        except Exception as e:
            logger.error(f"Error scoring article {article.id}: {e}")
            self.db.rollback()
            raise
```

## Gestion d'Erreur & S√©curit√©

### Python (Backend)

**Gestion d'erreurs**

```python
# ‚ùå MAUVAIS
def fetch_data():
    response = requests.get(url)
    return response.json()

# ‚úÖ BON
async def fetch_data():
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                url,
                timeout=30.0,
                headers={"User-Agent": settings.USER_AGENT}
            )
            response.raise_for_status()
            return response.json()
    except httpx.HTTPError as e:
        logger.error(f"HTTP error fetching {url}: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise
```

**Validation Pydantic**

```python
from pydantic import BaseModel, Field, field_validator

class ArticleCreate(BaseModel):
    title: str = Field(..., min_length=1, max_length=500)
    url: str = Field(..., pattern=r'^https?://')
    content: Optional[str] = Field(None, max_length=50000)

    @field_validator('url')
    @classmethod
    def validate_url(cls, v: str) -> str:
        if not v.startswith(('http://', 'https://')):
            raise ValueError('URL must start with http:// or https://')
        return v
```

### TypeScript (Frontend)

**Error Boundaries**

```typescript
'use client';

import { Component, ReactNode } from 'react';

interface Props {
  children: ReactNode;
  fallback?: ReactNode;
}

interface State {
  hasError: boolean;
}

export class ErrorBoundary extends Component<Props, State> {
  constructor(props: Props) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError() {
    return { hasError: true };
  }

  componentDidCatch(error: Error, errorInfo: any) {
    console.error('Error caught by boundary:', error, errorInfo);
    // Log to error tracking service (Sentry, etc.)
  }

  render() {
    if (this.state.hasError) {
      return this.props.fallback || (
        <div className="p-4 border border-red-500 rounded">
          <h2 className="text-red-500 font-bold">Something went wrong</h2>
          <button onClick={() => this.setState({ hasError: false })}>
            Try again
          </button>
        </div>
      );
    }

    return this.props.children;
  }
}
```

**Validation Zod**

```typescript
import { z } from "zod";

export const articleSchema = z.object({
  title: z.string().min(1).max(500),
  url: z.string().url(),
  content: z.string().max(50000).optional(),
  score: z.number().min(0).max(100),
  category: z.enum(["healthtech", "blockchain", "dev", "other"]),
});

export type Article = z.infer<typeof articleSchema>;
```

### S√©curit√©

**Secrets Management**

```bash
# .env (JAMAIS commit√©)
DATABASE_URL=postgresql://user:password@localhost:5432/techwatch
REDIS_URL=redis://localhost:6379/0
ANTHROPIC_API_KEY=sk-ant-xxx
SECRET_KEY=xxx

# .env.example (commit√©)
DATABASE_URL=postgresql://user:password@localhost:5432/techwatch
REDIS_URL=redis://localhost:6379/0
ANTHROPIC_API_KEY=your_api_key_here
SECRET_KEY=your_secret_key_here
```

**CORS Configuration**

```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Frontend URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

**SQL Injection Prevention**

```python
# ‚ùå DANGEREUX
query = f"SELECT * FROM articles WHERE title = '{user_input}'"

# ‚úÖ S√âCURIS√â (param√©tris√©)
query = select(Article).where(Article.title == user_input)
```

## Instructions pour l'IA (Claude)

### Comportement g√©n√©ral

1. **Context Awareness**: Toujours v√©rifier dans quel dossier tu travailles (`backend/`, `frontend/`, `database/`, `powerbi/`)

2. **Type Safety Strict**:
   - Python : Utiliser les type hints partout
   - TypeScript : ZERO `any`, utiliser les types stricts
   - SQL : Utiliser les types PostgreSQL appropri√©s

3. **Performance First**:
   - Backend : Async/await partout (httpx, asyncpg)
   - Frontend : Lazy loading, pagination, React.memo
   - DB : Index sur colonnes filtr√©es, vues mat√©rialis√©es si besoin

4. **Testing Mindset**:
   - √âcrire des tests pour la logique critique
   - Mock les appels API externes
   - Tests unitaires + tests d'int√©gration

### Ce que tu DOIS faire

‚úÖ Proposer des solutions modulaires (1 fichier = 1 responsabilit√©)
‚úÖ Utiliser les composants shadcn/ui existants
‚úÖ Documenter les fonctions complexes (docstrings Python, JSDoc TypeScript)
‚úÖ Logger les erreurs avec contexte
‚úÖ Valider les inputs (Pydantic, Zod)
‚úÖ G√©rer les cas limites (donn√©es nulles, timeout r√©seau)
‚úÖ Suivre les conventions de nommage du projet

### Ce que tu NE DOIS PAS faire

‚ùå Modifier les configs Docker/Compose sans demande explicite
‚ùå Introduire de nouvelles d√©pendances lourdes sans justification
‚ùå Laisser des `console.log`, `print()`, `fmt.Println` de debug
‚ùå Utiliser `any` en TypeScript ou ignorer les type hints Python
‚ùå Faire des appels synchrones bloquants (toujours async)
‚ùå Hardcoder des secrets ou tokens
‚ùå Cr√©er des fichiers de +500 lignes sans d√©coupage logique

### Patterns recommand√©s

**Repository Pattern (Backend)**

```python
# repositories/article_repository.py
class ArticleRepository:
    def __init__(self, db: Session):
        self.db = db

    async def get_by_id(self, article_id: int) -> Optional[Article]:
        return self.db.query(Article).filter(Article.id == article_id).first()

    async def create(self, article: Article) -> Article:
        self.db.add(article)
        self.db.commit()
        self.db.refresh(article)
        return article
```

**Custom Hooks (Frontend)**

```typescript
// hooks/useArticles.ts
import { useQuery } from "@tanstack/react-query";
import { apiClient } from "@/lib/api-client";

export const useArticles = (filters?: ArticleFilters) => {
  return useQuery({
    queryKey: ["articles", filters],
    queryFn: () => apiClient.getArticles(filters),
    staleTime: 5 * 60 * 1000, // 5 minutes
  });
};
```

**Factory Pattern (Scrapers)**

```python
# scrapers/factory.py
class ScraperFactory:
    _scrapers = {
        'reddit': RedditScraper,
        'hackernews': HackerNewsScraper,
        'devto': DevToScraper,
    }

    @classmethod
    def create_scraper(cls, source_type: str) -> BaseScraper:
        scraper_class = cls._scrapers.get(source_type)
        if not scraper_class:
            raise ValueError(f"Unknown scraper type: {source_type}")
        return scraper_class()
```

## Workflows de D√©veloppement

### Feature Development (feature par feature)

1. **Backend First**

   ```bash
   # Cr√©er migration DB
   alembic revision --autogenerate -m "add_trends_table"
   alembic upgrade head

   # Cr√©er model + schema
   # Cr√©er service
   # Cr√©er route API
   # Tester avec curl/Postman
   ```

2. **Frontend Second**

   ```bash
   # Cr√©er types TypeScript
   # Cr√©er hook TanStack Query
   # Cr√©er composant UI
   # Int√©grer dans page
   ```

3. **Power BI Last**
   ```bash
   # Cr√©er vue SQL optimis√©e
   # Connecter Power BI √† PostgreSQL
   # Cr√©er visualisations
   # Publier + embed dans frontend
   ```

### Testing

**Backend (Pytest)**

```python
# tests/test_scrapers/test_reddit.py
import pytest
from app.scrapers.reddit import RedditScraper

@pytest.mark.asyncio
async def test_reddit_scraper():
    scraper = RedditScraper()
    keywords = ["python", "fastapi"]

    async with scraper:
        articles = await scraper.fetch_articles(keywords, max_results=10)

    assert len(articles) > 0
    assert all('title' in a for a in articles)
    assert all('url' in a for a in articles)
```

**Frontend (Vitest)**

```typescript
// components/__tests__/ArticleCard.test.tsx
import { render, screen } from '@testing-library/react';
import { ArticleCard } from '../ArticleCard';

describe('ArticleCard', () => {
  it('renders article title', () => {
    const article = {
      id: '1',
      title: 'Test Article',
      url: 'https://example.com',
      score: 85,
      category: 'dev'
    };

    render(<ArticleCard article={article} />);
    expect(screen.getByText('Test Article')).toBeInTheDocument();
  });
});
```

## Commandes Utiles

### Infrastructure

```bash
# Lancer tous les services
docker-compose up -d

# Voir les logs
docker-compose logs -f backend
docker-compose logs -f celery

# Rebuild apr√®s changement de d√©pendances
docker-compose up -d --build

# Stop & cleanup
docker-compose down -v
```

### Backend

```bash
# Installation
cd backend
poetry install

# Lancer en dev
poetry run uvicorn app.main:app --reload --port 8000

# Migrations DB
poetry run alembic upgrade head
poetry run alembic revision --autogenerate -m "description"

# Lancer Celery worker
poetry run celery -A app.tasks.celery_app worker --loglevel=info

# Lancer Celery beat (scheduler)
poetry run celery -A app.tasks.celery_app beat --loglevel=info

# Tests
poetry run pytest
poetry run pytest --cov=app tests/

# Linting
poetry run ruff check .
poetry run ruff format .
```

### Frontend

```bash
# Installation
cd frontend
npm install

# Dev
npm run dev

# Build
npm run build
npm run start

# Tests
npm run test
npm run test:ui

# Linting
npm run lint
npm run format
```

### Database

```bash
# Se connecter √† PostgreSQL
docker-compose exec postgres psql -U user -d techwatch

# Backup
docker-compose exec postgres pg_dump -U user techwatch > backup.sql

# Restore
docker-compose exec -T postgres psql -U user techwatch < backup.sql

# Voir les tables
\dt

# Voir une vue
SELECT * FROM vw_articles_daily_stats LIMIT 10;
```

## M√©triques de Succ√®s

### Techniques

- ‚úÖ API Response time : <200ms (95th percentile)
- ‚úÖ Scraping : 100+ articles/jour
- ‚úÖ NLP Scoring : <2s par article
- ‚úÖ Frontend First Load : <2s (Lighthouse)
- ‚úÖ Zero downtime deployments

### Business

- ‚úÖ Pr√©cision : >80% articles pertinents (score >50)
- ‚úÖ Temps √©conomis√© : 90min/jour de veille manuelle
- ‚úÖ Taux de lecture : >70% pour articles score >70
- ‚úÖ D√©tection tendances : 3-5 jours avant mainstream

## Notes Sp√©cifiques au Projet

### Power BI Embedded

**Configuration Token**

```typescript
// lib/powerbi-config.ts
import { models } from "powerbi-client";

export const getPowerBIConfig = (
  embedToken: string,
): models.IReportEmbedConfiguration => ({
  type: "report",
  tokenType: models.TokenType.Embed,
  accessToken: embedToken,
  embedUrl: process.env.NEXT_PUBLIC_POWERBI_EMBED_URL!,
  id: process.env.NEXT_PUBLIC_POWERBI_REPORT_ID!,
  settings: {
    panes: {
      filters: { expanded: false, visible: true },
    },
    background: models.BackgroundType.Transparent,
  },
});
```

### NLP Scoring Algorithm

Le scoring combine 3 approches :

1. **Exact Match** (40%) : Le mot-cl√© appara√Æt tel quel
2. **Semantic Similarity** (30%) : Similarit√© avec spaCy embeddings
3. **TF-IDF Cosine** (30%) : Importance du terme dans le document

Score final = moyenne pond√©r√©e √ó poids du mot-cl√©

### Celery Beat Schedule

```python
# tasks/celery_app.py
from celery.schedules import crontab

app.conf.beat_schedule = {
    'scrape-every-6-hours': {
        'task': 'app.tasks.scraping.scrape_all_sources',
        'schedule': crontab(hour='*/6'),  # Toutes les 6h
    },
    'send-daily-digest': {
        'task': 'app.tasks.email.send_daily_digest',
        'schedule': crontab(hour=8, minute=0),  # 8h00 chaque jour
    },
}
```

---

**Derni√®re mise √† jour** : D√©cembre 2024
**Version** : 1.0.0
**Auteur** : Tom (Epitech Lyon)
